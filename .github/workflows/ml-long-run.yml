name: ML Long Training (72h, self-hosted GPU)

on:
  workflow_dispatch:
    inputs:
      run_name:
        description: "Имя запуска/эксперимента"
        required: false
        default: "exp-${{ github.run_number }}"
  push:
    branches: [ main ]

jobs:
  train-long:
    runs-on: [self-hosted, windows, gpu]
    timeout-minutes: 4320 # 72 часа
    env:
      PYTHON_VERSION: "3.11"
      LOG_DIR: logs/actions-run-${{ github.run_id }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure log directory
        shell: pwsh
        run: New-Item -ItemType Directory -Force -Path "$env:LOG_DIR" | Out-Null

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install requirements
        shell: pwsh
        run: |
          python -m pip install --upgrade pip
          if (Test-Path "requirements.txt") {
            python -m pip install -r requirements.txt
          } else {
            python -m pip install torch --index-url https://download.pytorch.org/whl/cu121
            python -m pip install numpy pandas scikit-learn matplotlib
          }

      - name: Print GPU info (nvidia-smi)
        shell: pwsh
        continue-on-error: true
        run: |
          $smi = "C:\Program Files\NVIDIA Corporation\NVSMI\nvidia-smi.exe"
          if (Test-Path $smi) {
            & "$smi" | Tee-Object -FilePath "$env:LOG_DIR\nvidia-smi.txt"
          } else {
            Write-Host "nvidia-smi not found."
          }

      - name: Quick CUDA checks (PyTorch/TensorFlow)
        shell: pwsh
        continue-on-error: true
        run: |
          python - << 'PY'
import sys
def safe(fn):
    try: fn()
    except Exception as e: print("ERROR:", e, file=sys.stderr)
safe(lambda: __import__("torch"))
import torch
print("Torch:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("Device count:", torch.cuda.device_count())
    print("Device 0:", torch.cuda.get_device_name(0))
safe(lambda: __import__("tensorflow"))
import tensorflow as tf
print("TF:", tf.__version__)
print("GPUs:", tf.config.list_physical_devices('GPU'))
PY

      - name: Start background GPU monitor
        shell: pwsh
        continue-on-error: true
        run: |
          if (Test-Path "scripts\gpu_monitor.py") {
            python scripts\gpu_monitor.py --interval 60 --out "$env:LOG_DIR\gpu_usage.csv" &
          } else {
            Write-Host "scripts/gpu_monitor.py not found (monitoring skipped)."
          }

      - name: Run training
        shell: pwsh
        run: |
          if (Test-Path "scripts\train.py") {
            python scripts\train.py 2>&1 | Tee-Object -FilePath "$env:LOG_DIR\train.log"
          } else {
            Write-Host "scripts/train.py not found. Running placeholder..."
            python - << 'PY' 2>&1 | Tee-Object -FilePath "$env:LOG_DIR\train.log"
import time
print("Placeholder long run started...")
for i in range(60):  # ~60 минут демонстрации
    print(f"step {i} ...")
    time.sleep(60)
print("Placeholder long run finished.")
PY

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: "${{ github.workflow }}-${{ github.run_id }}"
          path: |
            ${{ env.LOG_DIR }}/
            models/
            results/
          if-no-files-found: ignore
          retention-days: 14