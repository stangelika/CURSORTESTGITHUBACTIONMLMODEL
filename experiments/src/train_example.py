#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü—Ä–∏–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ GPU —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
"""

import os
import time
import json
from datetime import datetime
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

def create_experiment_dir(base_path="../results"):
    """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    exp_dir = os.path.join(base_path, f"exp_{timestamp}")
    os.makedirs(exp_dir, exist_ok=True)
    os.makedirs(os.path.join(exp_dir, "checkpoints"), exist_ok=True)
    os.makedirs(os.path.join(exp_dir, "logs"), exist_ok=True)
    return exp_dir

class SimpleCNN(nn.Module):
    """–ü—Ä–æ—Å—Ç–∞—è CNN –¥–ª—è CIFAR-10/MNIST"""
    def __init__(self, num_classes=10):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # –¥–ª—è CIFAR-10 32x32
        self.fc2 = nn.Linear(512, num_classes)
        self.dropout = nn.Dropout(0.5)
        
    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 64 * 8 * 8)
        x = self.dropout(torch.relu(self.fc1(x)))
        x = self.fc2(x)
        return x

def train_model(num_epochs=5, batch_size=32, learning_rate=0.001):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏"""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üöÄ Using device: {device}")
    if torch.cuda.is_available():
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    exp_dir = create_experiment_dir()
    print(f"üìÅ Experiment directory: {exp_dir}")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    config = {
        "timestamp": datetime.now().isoformat(),
        "device": str(device),
        "num_epochs": num_epochs,
        "batch_size": batch_size,
        "learning_rate": learning_rate,
        "model": "SimpleCNN",
        "dataset": "CIFAR-10"
    }
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    with open(os.path.join(exp_dir, "config.json"), "w") as f:
        json.dump(config, f, indent=2)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    print("üìä Preparing data...")
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = SimpleCNN(num_classes=10).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    print(f"üß† Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # –õ–æ–≥ —Ñ–∞–π–ª
    log_file = os.path.join(exp_dir, "logs", "training.log")
    
    # –°–∏–º—É–ª—è—Ü–∏—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ (–¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    print("üèÉ Starting training simulation...")
    training_log = []
    
    for epoch in range(num_epochs):
        epoch_start = time.time()
        
        # –°–∏–º—É–ª—è—Ü–∏—è forward/backward pass –Ω–∞ GPU
        dummy_input = torch.randn(batch_size, 3, 32, 32).to(device)
        dummy_target = torch.randint(0, 10, (batch_size,)).to(device)
        
        optimizer.zero_grad()
        outputs = model(dummy_input)
        loss = criterion(outputs, dummy_target)
        loss.backward()
        optimizer.step()
        
        epoch_time = time.time() - epoch_start
        loss_val = loss.item()
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        log_entry = {
            "epoch": epoch + 1,
            "loss": loss_val,
            "time": epoch_time,
            "gpu_memory": torch.cuda.memory_allocated(device) / 1024**2 if torch.cuda.is_available() else 0
        }
        training_log.append(log_entry)
        
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss_val:.4f}, Time: {epoch_time:.2f}s")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞ –∫–∞–∂–¥—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–ø–æ—Ö
        if (epoch + 1) % 2 == 0:
            checkpoint = {
                'epoch': epoch + 1,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': loss_val,
            }
            torch.save(checkpoint, os.path.join(exp_dir, "checkpoints", f"checkpoint_epoch_{epoch+1}.pth"))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    torch.save(model.state_dict(), os.path.join(exp_dir, "final_model.pth"))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–≥–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
    with open(log_file, "w") as f:
        json.dump(training_log, f, indent=2)
    
    print(f"‚úÖ Training completed! Results saved to: {exp_dir}")
    print(f"üìã Artifacts: config.json, final_model.pth, checkpoints/, logs/training.log")
    
    return exp_dir, training_log

if __name__ == "__main__":
    print("üî• PyTorch GPU Training Example")
    print("=" * 50)
    
    # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    exp_dir, log = train_model(num_epochs=3, batch_size=16)
    
    print("\nüìä Training Summary:")
    for entry in log:
        print(f"  Epoch {entry['epoch']}: Loss={entry['loss']:.4f}, GPU Memory={entry['gpu_memory']:.1f}MB")
